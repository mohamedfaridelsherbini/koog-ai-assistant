# Koog AI Assistant Helm Chart Values

# Global settings
global:
  imageRegistry: ghcr.io/mohamedfaridelsherbini/koog-ai-assistant
  imageTag: "1.0.0"
  imagePullPolicy: IfNotPresent

# Koog AI Assistant settings
koogAi:
  enabled: true
  replicaCount: 3
  
  image:
    repository: ghcr.io/mohamedfaridelsherbini/koog-ai-assistant
    tag: "1.0.0"
    pullPolicy: IfNotPresent
  
  service:
    type: ClusterIP
    port: 8080
    targetPort: 8080
  
  resources:
    requests:
      memory: "512Mi"
      cpu: "250m"
    limits:
      memory: "2Gi"
      cpu: "1"
  
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 10
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80
  
  nodeSelector: {}
  tolerations: []
  affinity: {}

# Ollama LLM Service settings
ollama:
  enabled: true
  replicaCount: 1
  
  image:
    repository: ollama/ollama
    tag: "latest"
    pullPolicy: IfNotPresent
  
  service:
    type: ClusterIP
    port: 11434
    targetPort: 11434
  
  resources:
    requests:
      memory: "4Gi"
      cpu: "2"
    limits:
      memory: "16Gi"
      cpu: "8"
  
  persistence:
    enabled: true
    size: 100Gi
    storageClass: ""
    accessMode: ReadWriteOnce
  
  nodeSelector:
    kubernetes.io/os: linux
  
  tolerations:
    - key: "nvidia.com/gpu"
      operator: "Exists"
      effect: "NoSchedule"
  
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
          - key: accelerator
            operator: In
            values: ["nvidia-tesla", "nvidia-gpu"]

# Ingress settings
ingress:
  enabled: false
  className: ""
  annotations: {}
  hosts:
    - host: koog-ai.local
      paths:
        - path: /
          pathType: Prefix
  tls: []

# LoadBalancer settings
loadBalancer:
  enabled: true
  type: LoadBalancer
  port: 80
  targetPort: 8080

# Configuration
config:
  ollamaHost: "ollama-service:11434"
  webPort: "8080"
  modelCacheTtl: "30"
  logLevel: "INFO"
  debug: "false"
  environment: "production"
  maxConcurrentRequests: "100"
  requestTimeout: "300"
  healthCheckInterval: "30"
  healthCheckTimeout: "10"
  healthCheckRetries: "3"

# Monitoring
monitoring:
  enabled: false
  serviceMonitor:
    enabled: false
    interval: 30s
    scrapeTimeout: 10s

# Security
security:
  podSecurityContext:
    fsGroup: 2000
  containerSecurityContext:
    allowPrivilegeEscalation: false
    runAsNonRoot: true
    runAsUser: 1000
    capabilities:
      drop:
        - ALL

# Service Account
serviceAccount:
  create: true
  annotations: {}
  name: ""

# Pod Disruption Budget
podDisruptionBudget:
  enabled: true
  minAvailable: 1

# Network Policy
networkPolicy:
  enabled: false
  ingress: []
  egress: []
